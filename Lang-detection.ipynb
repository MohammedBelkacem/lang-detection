{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premium-popularity",
   "metadata": {},
   "source": [
    "<SPAN STYLE=\"font-size:14.0pt;font-family:'Calibri'\"><b>Tifin n tualyt neɣ aɛqal n tutlayt<br>\n",
    "Sɣur Muḥend Belqasem Copyright - 2021</SPAN>\n",
    "    <br>\n",
    "    Ahilen-a, ttwaheggan-d i usemsel awurman n tutlayt. D tasleḍt n tesnalɣa n tutlayt akken ad nizmir ad d-naf tutlayt n yiḍrisen. Ladɣa ticki aḍris yegber ddeqs n tutlayin "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-perry",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tamawt:\n",
    "<SPAN STYLE=\"font-size:14.0pt;font-family:'Calibri'\">Ahilen-a ur teddun ara i tutlayin yettwarun seg uyeffus s azelmaḍ am taɛrabt. Ahulen-a ad ddun kan i tutlayin yettwarun seg uẓelmaḍ s ayeffus akken yebɣu yella unagraw n tira ama d alaṭini am teqbaylit, neɣ tifinaɣ, ... </SPAN>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-journalist",
   "metadata": {},
   "source": [
    "# Azdam neɣ asader n tegrummiwin n yisefka:\n",
    "\n",
    "<SPAN STYLE=\"font-size:14.0pt;font-family:'Calibri'\"> Isefka meṛṛa ara nseqdec deg wahil-a, kkan-d seg Tatoeba.\n",
    "Dagi ad nseqdec isefka n tutlayin-a: Taqbaylit, Tafransist, Taspanit, Takatalant, Taglizit, taṭelyanit, Tapurtugit, Talmanit.\n",
    "    \n",
    "Deg wahil ddaw-a, ad nseqdec tamkarḍit <b>wget<b/> n <b>Python<b/>. \n",
    "    \n",
    "Deg tazwara, sbedd Python 3.6. Ddu ɣer usmel n Python, sader-d Python 3.6 64 bits i Windows neɣ Linux.\n",
    "\n",
    "Sakin sbedd tamkarḍit wget akka:\n",
    "<b>pip install wget</b>\n",
    "\n",
    "Ur tettut ara d akken tlaq tuqqna Internet i uzdam n yifuyla n tegrummiwin n tutlayin ara tesqedceḍ.\n",
    "\n",
    "- Ifecka:\n",
    "\n",
    "Wid yessnen Jupyter, zemren ad d-sadren afaylu-a seg Github, seg tansa-a:\n",
    "    \n",
    "Wiyaḍ, zemren ad d-kksen ahilen-a, sakin ad ten-selkmen s umesres n PyCharm, PyScripter neɣ Eclipse.</SPAN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "# Tafelwit n tutlayin, azdam ad yettwag s useqdec n tengalin-nsent. Tingalin-a d tid n ISO 639-3.\n",
    "# Wali ma tella tutlayt-nniḍen i tebɣiḍ deg Tatoeba tatoeba.org uqbel ad ternuḍ tanglat-a ɣer tfelwit ddaw-a.\n",
    "# Maca, ahil-a i d-iteddun ur iteddu ara i taɛrabt neɣ tutlayin yettwarun seg uyeffus s azelmaḍ\n",
    "tutlayin=['kab','fra','spa','cat','eng','ita','por','deu']\n",
    "\n",
    "# Tabadut n twuri n uzdam n yisefka n tutlayin\n",
    "def zdem (tutlayin):\n",
    "\n",
    " for tutlayt in tutlayin:\n",
    "    # aseɣwen n usader\n",
    "    aseɣwen=\"https://downloads.tatoeba.org/exports/per_language/\"+tutlayt+\"/\"+tutlayt+\"_sentences.tsv.bz2\"\n",
    "    # Isem n ufaylu\n",
    "    isem_ufaylu=tutlayt+\"_sentences.tsv.bz2\"\n",
    "\n",
    "    wget.download(aseɣwen)\n",
    "# asiwel n twuri n uzdams umuddun n wumuɣ n tutlayin i nebɣa d nesleḍ\n",
    "zdem(tutlayin)\n",
    "print ('Azdam ifukk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-while",
   "metadata": {},
   "source": [
    "# Tukksa n usekussem n yifuyla n tegrummiwin n yisefka.\n",
    "Deg windows, semres winrar neɣ winzip.\n",
    "<img src=\"kab.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-economy",
   "metadata": {},
   "source": [
    "# Aheggi n tegrummiwin\n",
    "Ifuyla i d-nessader seg Tatoeba, gebren kra n telɣut neɣ isallen ur nettiḥwiǧi ara deg wahilen-a. Ihi ilaq ad ten-nekkes. Ddaw-a ad tafem ahil ara yessuffɣen kan tifyar seg yifuyla i d-nessader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changing-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tafelwit n tutlayin\n",
    "tutlayin=['kab','fra','spa','cat','eng','ita','por','deu']\n",
    "\n",
    "# Tabadut n twuri ara d-yessuffɣen tifyar seg yal afaylu i d-nessader seg Tatoeba\n",
    "\n",
    "def aheggi_n_tegrummiwin (tutlayin):\n",
    " # yal tutlayt\n",
    " for tutlayt in tutlayin:\n",
    "   # ad d-nawi isem n ufaylu n tutlayt i d-nessader\n",
    "    isem_ufaylu=tutlayt+\"_sentences.tsv\"\n",
    "    #ad d-nedli  ayalu amaynut i tefyar n tutlayt-a\n",
    "    h= open(tutlayt+\".txt\",\"w+\",encoding='utf-8')\n",
    "    # Ad d-nḍum akk iduren n ufaylu. Yal adur tella deg-s tefyirt\n",
    "    for ligne in open(isem_ufaylu,encoding='utf-8'):\n",
    "        a=ligne.split('\\t') # ad nebḍu adur s usekkil n trigla neɣ tabulation\n",
    "        h.write(a[2]) # ad d-nekkes taxxamt tis 3 acku dinna i tella tefyirt. Sakin ad tt-naru deg ufaylu amaynut.\n",
    "    h.close()\n",
    "aheggi_n_tegrummiwin(tutlayin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-genius",
   "metadata": {},
   "source": [
    "# aseɣti n tuccḍiwin deg tegrumma n tefyar n tutlayt taqbaylit\n",
    "Ddeqs n tuccḍiwin i nettaf deg yisefka-a. Tuget d isekkilen. Acku yal wa acu unasiw i yessemras. Maca, ur nezmir ara ad nseɣti s wudem awurman, tuccḍiwin i icudden ɣer tira neɣ tajerrumt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sublime-shoot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aseɣti yemmed\n"
     ]
    }
   ],
   "source": [
    "izwilen=['0','1','2','3','4','5','6','7','8','9']\n",
    "asenqeḍ=[\"—\",'ʻ','₂','°','€','–','«','»','”','“',' ','!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "agemmay_ameẓẓyan=['a', 'b', 'c', 'č', 'd', 'ḍ', 'e', 'f', 'g', 'ǧ', 'h', \"ḥ\", 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'ɣ', 'r', 'ṛ', 's', 'ṣ', 't', 'ṭ', 'u', 'v', 'w', 'ɛ', 'x', 'y', 'z', 'ẓ']\n",
    "agemmay_ameqqran=['A', 'B', 'C', 'Č', 'D', 'Ḍ', 'E', 'F', 'G', 'Ǧ', 'H', \"Ḥ\", 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'Ɣ', 'R', 'Ṛ', 'S', 'Ṣ', 'T', 'Ṭ', 'U', 'V', 'W', 'Ɛ', 'X', 'Y', 'Z', 'Ẓ']\n",
    "\n",
    "def aseɣti_n_tuccḍiwin(tafyirt):\n",
    "    tafyirt=tafyirt.strip()\n",
    "    tafyirt=tafyirt.replace('\\t','')\n",
    "    tafyirt=tafyirt.replace(' ',' ')\n",
    "    tafyirt=tafyirt.replace(' ',' ')\n",
    "    tafyirt=tafyirt.replace('ƫ','tt')\n",
    "    tafyirt=tafyirt.replace('々',' ')\n",
    "    tafyirt=tafyirt.replace('□',' ')\n",
    "    tafyirt=tafyirt.replace('ß','Beta')\n",
    "    tafyirt=tafyirt.replace('ǰ','j')\n",
    "    tafyirt=tafyirt.replace('é','e')\n",
    "    tafyirt=tafyirt.replace('è','e')\n",
    "    tafyirt=tafyirt.replace('\\n','')\n",
    "    tafyirt=tafyirt.replace('Γ','Ɣ')\n",
    "    tafyirt=tafyirt.replace('ε','ɛ')\n",
    "    tafyirt=tafyirt.replace('Ԑ','Ɛ')\n",
    "    tafyirt=tafyirt.replace(' ',' ')\n",
    "    tafyirt=tafyirt.replace('ğ','ǧ')\n",
    "    tafyirt=tafyirt.replace('γ','ɣ')\n",
    "    tafyirt=tafyirt.replace('γ','ɣ')\n",
    "    #tafyirt=tafyirt.replace('','ɣ')\n",
    "    tafyirt=tafyirt.replace('ţ','tt')\n",
    "    tafyirt=tafyirt.replace('ț','tt')\n",
    "    tafyirt=tafyirt.replace('tttt','tt')\n",
    "    tafyirt=tafyirt.replace('ã','a')\n",
    "    tafyirt=tafyirt.replace('Ţ','Tt')\n",
    "    tafyirt=tafyirt.replace('Ţttt','Tt')\n",
    "    tafyirt=tafyirt.replace('Σ','Ɛ')\n",
    "    tafyirt=tafyirt.replace('‑','.')\n",
    "    tafyirt=tafyirt.replace('…',',')\n",
    "    tafyirt=tafyirt.replace('ï','i')\n",
    "    tafyirt=tafyirt.replace('ĉ','č')\n",
    "    tafyirt=tafyirt.replace('ḅ','b')\n",
    "    tafyirt=tafyirt.replace('î','i')\n",
    "    tafyirt=tafyirt.replace('í','i')\n",
    "    tafyirt=tafyirt.replace('ë','e')\n",
    "    tafyirt=tafyirt.replace('É','E')\n",
    "    tafyirt=tafyirt.replace('Ğ','Ǧ')\n",
    "    tafyirt=tafyirt.replace('Г','Ɣ')\n",
    "    tafyirt=tafyirt.replace('ʷ','')\n",
    "    tafyirt=tafyirt.replace('','ɛ')\n",
    "    tafyirt=tafyirt.replace('ḷ','l')\n",
    "    tafyirt=tafyirt.replace('ⵥ','')\n",
    "    tafyirt=tafyirt.replace('ę','ɛ')\n",
    "    tafyirt=tafyirt.replace('ḳ','k')\n",
    "    tafyirt=tafyirt.replace('ṃ','m')\n",
    "    #tafyirt=tafyirt.replace(,'')\n",
    "    j=0\n",
    "    ok=True\n",
    "    for i in tafyirt:\n",
    "\n",
    "         if i not in asenqeḍ and i not in agemmay_ameqqran and i not in agemmay_ameẓẓyan and i not in izwilen:\n",
    "            ok=False\n",
    "         j=j+1\n",
    "    return tafyirt+'\\n',ok\n",
    "\n",
    "#Tafelwit n tutlayin\n",
    "tutlayin=['kab']\n",
    "# Tabadut n twuri ara d-yessuffɣen tifyar seg yal afaylu i d-nessader seg Tatoeba\n",
    "\n",
    "def aheggi_n_tegrummiwin (tutlayin):\n",
    " # yal tutlayt\n",
    " for tutlayt in tutlayin:\n",
    "   # ad d-nawi isem n ufaylu n tutlayt i d-nessader\n",
    "    isem_ufaylu=tutlayt+\"_sentences.tsv\"\n",
    "    #ad d-nedli  ayalu amaynut i tefyar n tutlayt-a\n",
    "    h= open(tutlayt+\".txt\",\"w+\",encoding='utf-8')\n",
    "    l= open(tutlayt+\"-notkab.txt\",\"w+\",encoding='utf-8')\n",
    "    # Ad d-nḍum akk iduren n ufaylu. Yal adur tella deg-s tefyirt\n",
    "    for ligne in open(isem_ufaylu,encoding='utf-8'):\n",
    "        #print (ligne)\n",
    "        a=ligne.split('\\t') # ad nebḍu adur s usekkil n trigla neɣ tabulation\n",
    "\n",
    "        tafyirt,ok=aseɣti_n_tuccḍiwin(a[2])\n",
    "        if ok:\n",
    "         h.write(tafyirt) # ad d-nekkes taxxamt tis 3 acku dinna i tella tefyirt. Sakin ad tt-naru deg ufaylu amaynut.\n",
    "        else:\n",
    "            l.write(a[2])\n",
    "    h.close()\n",
    "aheggi_n_tegrummiwin(tutlayin)\n",
    "print(\"aseɣti yemmed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-bones",
   "metadata": {},
   "source": [
    "# Asluɣmu n yisefka\n",
    "Ad nseqdec tatiknikt n N-grams akkken ad nselmed n uselkim amek i ttemseḍfaṛen yisekkilen n ugemmay n teqbaylit deg yiḍrisen n teqbaylit.\n",
    "Ddaw-a, ad tafem alguritm n usluɣmu d usnulfu n tneɣruft n uɛqal n tutlayt taqbaylit.\n",
    "Ad nsebded nltk d temkarḍiyin-nniḍen n Python akken ad nizmir adnseqdec tawuri.\n",
    "\n",
    "<b>Asebeddi n temkarḍiyin</b>\n",
    "Deg tdiwent n Windows neɣ Linux, aru:\n",
    "<b>pip install nltk re codecs numpy string</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def train_language(path,lang_name):\n",
    "    words_all = []\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    # Taɣuri n ufayu s usettengel unicode format s usemres n temkarḍit codecs\n",
    "    with codecs.open(path,\"r\",\"utf-8\") as filep:\n",
    "\n",
    "        for i,line in enumerate(filep):\n",
    "            line = line.lower()   # ad naru meṛṛa isekkilen s usekkil ameẓẓyan\n",
    "            line = re.sub(r\"\\d+\", \"\", line) # tukksa n yizwilen\n",
    "\n",
    "            if len(line) != 0:\n",
    "                line = line.translate(translate_table) # tukksa n usenqeḍ\n",
    "                words_all += line\n",
    "                words_all.append(\" \") # asdukkel n tefyar\n",
    "\n",
    "    all_str = ''.join(words_all)\n",
    "    all_str = re.sub(' +',' ',all_str) # asemselsi n yisekkilen ilmawen s yiwen kan n usekkil\n",
    "    seq_all = [i for i in all_str]\n",
    "\n",
    "    # Tukksa n bi-grams s usmizzwer-nsen s umḍan n tmeḍriwin\n",
    "    finder = BigramCollocationFinder.from_words(seq_all)\n",
    "    finder.apply_freq_filter(5)\n",
    "    bigram_model = finder.ngram_fd.items()\n",
    "    bigram_model = sorted(finder.ngram_fd.items(), key=lambda item: item[1],reverse=True)\n",
    "\n",
    "    \n",
    "    np.save(lang_name+\".npy\",bigram_model) # asekles n tneɣruft n tutlayt\n",
    "lang_name = ['kab','fra','spa','cat','eng','ita','por','deu']\n",
    "train_lang_path = ['kab.txt','fra.txt','spa.txt','cat.txt','eng.txt','ita.txt','por.txt','deu.txt']\n",
    "root=''\n",
    "for i,p in enumerate(train_lang_path):\n",
    "        train_language(root+p,lang_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-session",
   "metadata": {},
   "source": [
    "# Asemres n tneɣruft n tutlayt\n",
    "Ticki tella tneɣruft n tutlayt, aselkim ad yizmir i yiman-is ad d-yaf n wanta-tt tutlayt ideg ttwarunt tefyar. Aya, ad yettwaseqdec deg waṭas n tɣula am usismel awurman n yidlisen, imagraden, ... atg.\n",
    "Maca daɣen, ad nizmir ad nsismel tiyar s tutlayin yemgaraden xas ma xelḍent deg yiwen n yisemli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def test_language(path,language,total):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    lang_name = ['kab','fra','spa','cat','eng','ita','por','deu']\n",
    "    model = [np.load(lang+\".npy\",allow_pickle=True) for lang in lang_name]\n",
    "\n",
    "    with codecs.open(path,\"r\",\"utf-8\") as filep:\n",
    "        translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "        for l,line in enumerate(filep):\n",
    "\n",
    "            line = line.lower() # Ad nerr meṛṛa isekkilen d imeẓẓyanen\n",
    "            line = re.sub(r\"\\d+\", \"\", line)# tukksa n yizwilen\n",
    "            line = line.translate(translate_table) #tikksa n usenqeḍ\n",
    "\n",
    "            finder = BigramCollocationFinder.from_words(line)\n",
    "\n",
    "            freq_sum = np.zeros(len(lang_name))# 8 n tutlayin\n",
    "            for k,v in finder.ngram_fd.items():\n",
    "                isthere = 0\n",
    "                for i,lang in enumerate(lang_name):\n",
    "                    for key,f in model[i]:\n",
    "                        if k == key:\n",
    "                            freq_sum[i] = freq_sum[i]+(f*10000)/total[i]\n",
    "                            isthere = 1\n",
    "                            break\n",
    "                    if isthere == 0:\n",
    "                        freq_sum[i] = freq_sum[i] + 1\n",
    "\n",
    "            max_val = freq_sum.max()\n",
    "            index= freq_sum.argmax()\n",
    "            if max_val != 0:\n",
    "                if lang_name[index] == language:\n",
    "                    tp = tp + 1\n",
    "                else:\n",
    "                    fp = fp + 1\n",
    "            print (\"tp = \",tp,\"fp = \",fp,\" Taseqqart tafellayt =\", np.max(freq_sum),\" Tafelwit n tseqqar: \",freq_sum )\n",
    "            print(line)\n",
    "   \n",
    "\n",
    "\n",
    "root = \"\"\n",
    "lang_name = ['kab','fra','spa','cat','eng','ita','por','deu']\n",
    "no_of_bigms = []\n",
    "for i,lang in enumerate(lang_name):\n",
    "        model = np.load(lang+\".npy\",allow_pickle=True)\n",
    "        total = 0\n",
    "        for key,v in model:\n",
    "            total = total + v\n",
    "        no_of_bigms.append(total)\n",
    "        #print (total)\n",
    "\n",
    "train_lang_path = ['testkab.txt','testfra.txt','testspa.txt','testcat.txt','testeng.txt','testita.txt','testpor.txt','testdeu.txt']\n",
    "for i,p in enumerate(train_lang_path):\n",
    "  if lang_name[i]==\"kab\":\n",
    "         print (\"Testing of \",lang_name[i])\n",
    "         test_language(root+p,lang_name[i],no_of_bigms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
